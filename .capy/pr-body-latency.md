## Objective
Reduce TTFB and perceived latency on /api/agents/[id]/execute and /api/search via quick-win optimizations without changing business behavior.

## What changed
- Parallelized knowledge loading with concurrency cap (5), 2s per-file timeout, and hard caps:
  - /app/api/agents/[id]/execute/route.ts (TOTAL_CONTEXT_CAP=200KB)
  - /app/actions.ts getCustomAgentConfig (CAP=50KB)
- Added shared fetchWithTimeout helper (lib/http.ts) and applied to all external fetches above.
- Gated pre-stream URL fetching behind body.enrichWithWeb (default false). When enabled: max 1 URL, 1s timeout, 50KB text cap.
- Limited model fallbacks to one attempt per model, with order:
  - gemini-2.5-flash → gemini-2.0-flash → gemini-2.0-flash-exp (applies to default, libeller, and nomenclature flows)
- Added structured perf logs (console.info) for both endpoints capturing ttfb, files/kb, timeouts, urls, and selected model.
- Added a UI toggle “Web enrichment” (off by default) that passes enrichWithWeb in the request body.
- Kept existing sanitization and SSE behavior intact.

## Perf instrumentation (examples)
These logs are printed once the stream starts/finishes (console.info). Example lines:

- perf.agent_execute ttfb_ms=180 files=3 kb=176 timeouts=1 urls=0 model=gemini-2.5-flash
- perf.agent_execute_done ttfb_ms=180 files=3 kb=176 timeouts=1 urls=0 model=gemini-2.5-flash
- perf.search ttfb_ms=120 files=1 kb=48 timeouts=0 urls=0 model=gemini-2.5-flash
- perf.search ttfb_ms=140 files=1 kb=50 timeouts=1 urls=1 model=gemini-2.0-flash

Notes:
- In production, console statements obey Next.js removeConsole config.
- Timeouts include slow/aborted sources and are fail-soft.

## Acceptance checklist
- Web enrichment is off by default; when toggled on in UI, body.enrichWithWeb=true is sent.
- With enrichment off, first token should arrive sooner (no pre-stream URL fetch).
- Knowledge loading latency is non-additive per file thanks to concurrency (5) and per-file 2s timeout.
- Context size limits enforced: 200KB (execute), 50KB (custom agent config), 50KB (web text).
- Model fallbacks: single attempt per model, order maintained as requested.
- Streams unaffected; no change to user-visible message content.
- Fail-soft behavior: slow sources skipped, request does not fail.

## Configuration notes
- Optional read cache (Upstash Redis) is used if available by lib/db/index.ts
  - Required env vars for activation: UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN
  - If missing, requests proceed; a one-line info log indicates cache read is off

## Files changed
- app/api/agents/[id]/execute/route.ts
- app/actions.ts
- app/api/search/route.ts
- components/chat-interface.tsx
- lib/http.ts (new)

## Follow-up (optional)
- If desired, defer URL fetching (when enrichment is off) to an after() background task for subsequent suggestions without blocking first token.


₍ᐢ•(ܫ)•ᐢ₎ Generated by [Capy](https://capy.ai) ([view task](https://capy.ai/project/0ca3c02a-187d-443f-9fa8-e0cd8a42ea5e/task/47776d68-ad20-4cbb-a17b-2c6bab3ea3d4))